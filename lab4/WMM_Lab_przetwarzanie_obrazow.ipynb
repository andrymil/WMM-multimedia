{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"przetwarzanie_obrazow.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOud/f95lAuF10Uqv+nLpdw"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Dhiczj3ICPmL"},"source":["# Podstawy multimediów - ćwiczenia"]},{"cell_type":"markdown","metadata":{"id":"OqjeU1bXTFrp"},"source":["Do realizacji ćwiczeń i zadań laboratoryjnych z zakresu przetwarzania danych obrazowych wykorzystywany jest Python wraz z bibliotekami NumPy, Matplotlib i OpenCV.\r\n","\r\n","Pomocne tutoriale OpenCV:\r\n","[strona główna](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html),\r\n","[operacje podstawowe](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_core/py_basic_ops/py_basic_ops.html), \r\n","[operacje arytmetyczne](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_core/py_image_arithmetics/py_image_arithmetics.html), \r\n","[przetwarzanie obrazów](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_table_of_contents_imgproc/py_table_of_contents_imgproc.html)\r\n","(m.in.:\r\n","[zmiana przestrzeni kolorów](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_colorspaces/py_colorspaces.html#converting-colorspaces), \r\n","[filtracja](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_filtering/py_filtering.html#filtering),\r\n","[detekcja krawędzi](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_gradients/py_gradients.html),\r\n","[progowanie](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html),\r\n","[operacje morfologiczne](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html),\r\n","[histogramy](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_histograms/py_histogram_begins/py_histogram_begins.html)).\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"NwGdgCmSSS2u","executionInfo":{"status":"ok","timestamp":1615284185962,"user_tz":-60,"elapsed":1658,"user":{"displayName":"Grzegorz Galiński","photoUrl":"","userId":"07677391325184183263"}}},"source":["import time \r\n","\r\n","import cv2\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sztuH9dildyF"},"source":["# Dostęp do zewnętrznych plików w środowsiku Colab"]},{"cell_type":"markdown","metadata":{"id":"DJmcNcpsrTrt"},"source":["Pliki można przechowywać w folderze `sample_data` środowiska uruchomieniowego Colab - trzeba je tam wgrać, mogą zostać usunięte po zakończeniu sesji.\r\n","\r\n","Można też zamontować własny dysk Google Drive."]},{"cell_type":"code","metadata":{"id":"sZETBtQBlhPT"},"source":["##### dane w folderze środowiska uruchomieniowego\r\n","# data_dir = \"/content/sample_data/\" \r\n","\r\n","##### dane na Google Drive\r\n","from google.colab import drive\r\n","drive.mount(\"/content/drive\")\r\n","data_dir = \"/content/drive/My Drive/Colab Notebooks/PMUT_cwiczenia/\"\r\n","\r\n","##### dane w lokalnym folderze - uruchamianie skrytpu .py w lokalnym środowisku\r\n","# data_dir = \"./\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t7RpUVdmrcq7"},"source":["# Wczytanie obrazu"]},{"cell_type":"markdown","metadata":{"id":"Bi5ck3XPWFCX"},"source":["Tryby wczytywania obrazu:\r\n","* `cv2.IMREAD_COLOR` - obraz wczytany zostanie jako barwny, zawsze będzie miał trzy składowe (tablica 3D), nawet jeśli jest monochromatyczny;\r\n","* `cv2.IMREAD_GRAYSCALE` - obraz wczytany zostanie jako monochromatyczny, zawsze będzie miał tylko jedną składową (tablica 2D);\r\n","* `cv2.IMREAD_UNCHANGED` - obraz wczytany zostanie '*jak jest*', barwny lub monochromatyczny.\r\n","\r\n","Obraz zwracany jest jako tablica `numpy.ndarray`, można go przetwarzać jak każdą tablicę NumPy, m.in.:\r\n","* `image.shape` - wymiary obrazu: `shape[0]` - wysokość (liczba linii), `shape[1]` - szerokość (liczba pikseli w linii), `shape[2]` - liczba składowych (tylko dla obrazów barwnych);\r\n","* `image.dtype` - typ danych (liczby całkowite, liczby rzeczywiste, itp., np.: `np.uint8`, `np.float32`, `np.float64`);\r\n","* `image.min()`, `image.max()` - wartość minimalna/maksymalna.\r\n"]},{"cell_type":"code","metadata":{"id":"yL6kxSdWXFW5"},"source":["image = cv2.imread(data_dir+\"lena_mono.png\", cv2.IMREAD_UNCHANGED) \r\n","print(f\"image, wymiary: {image.shape}, typ danych: {image.dtype}, wartości: {image.min()} - {image.max()}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BKnIpl_1aPXA"},"source":["# Zapis do pliku.\r\n"]},{"cell_type":"markdown","metadata":{"id":"WMfmqh2tr0Vy"},"source":["Format zostanie automatycznie dobrany na podstawie nazwy pliku wyjściowego.\r\n","Możliwe jest ustawienie parametrów dodatkowych, zależnych od formatu wyjściowego (np. 'jakość' dla kodera JPEG)."]},{"cell_type":"code","metadata":{"id":"mA43KsyKYmVU"},"source":["cv2.imwrite(data_dir+\"out_image.png\", image)\r\n","cv2.imwrite(data_dir+\"out_image.jpg\", image)\r\n","cv2.imwrite(data_dir+\"out_image_quality50.jpg\", image, (cv2.IMWRITE_JPEG_QUALITY, 50))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z3nHRE0HpSjX"},"source":["# Wyświetlanie obrazu"]},{"cell_type":"markdown","metadata":{"id":"jw2ayO7latAW"},"source":["### Wyświetlanie z wykorzystaniem okna OpenCV"]},{"cell_type":"markdown","metadata":{"id":"6kEhCOmKr-K4"},"source":["W zależności od typu danych, zakładane są różne przedziały wartości pikseli:\r\n","* dla danych `uint8` - zakładany przedział wartości to [0, 255];\r\n","* dla danych `float32`/`float64` - zakładany jest przedział wartości [0, 1], a wartości pikseli są mnożone przez 255 do wyświetlenia.\r\n","\r\n","Żeby wyswietlić kilka obrazów, należy oknom nadać inny tytuł/nazwę."]},{"cell_type":"code","metadata":{"id":"9HMlYdzxbP8z"},"source":["# cv2.imshow(\"image\", image)\r\n","# image_float = image.astype(np.float32) \r\n","# # image_float = image*1.  ### wykorzystanie operacji arytmetycznej do zmiany typu danych\r\n","# print(f\"image_float, wymiary: {image_float.shape}, typ danych: {image_float.dtype}, wartości: {image_float.min()} - {image_float.max()}\")\r\n","# \r\n","# cv2.imshow(\"image float _bad\", image_float)  ### wyświetlony obraz będzie 'biały'\r\n","# cv2.imshow(\"image float\", image_float/255)   ### przeskalowanie wartości pikseli do przedziału [0, 1] - obraz wyświetlony prawidłowo\r\n","# \r\n","# cv2.waitKey(0)           ### oczekiwanie na naciśnięcie klawisza lub zamknięcie okien\r\n","# cv2.destroyAllWindows()  ### zniszczenie okien"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DzQpZyCmGLZs"},"source":["# def cv_imshow(img, img_title=\"image\"):\r\n","#     # cv2.namedWindow(img_title, cv2.WINDOW_AUTOSIZE) # cv2.WINDOW_NORMAL\r\n","#    \r\n","#     ##### przeskalowanie obrazu z rzeczywistymi wartościami pikseli, żeby jedną funkcją wywietlać obrazy różnych typów\r\n","#     if (img.dtype == np.float32) or (img.dtype == np.float64):\r\n","#         img_ = img/255\r\n","#     else:\r\n","#         img_ = img\r\n","#     cv2.imshow(img_title, img_)\r\n","#     cv2.waitKey(1)  ### oczekiwanie przez bardzo krótki czas - okno się wyświetli, ale program się nie zablokuje, tylko będzie kontynuowany\r\n","#\r\n","# cv_imshow(image, \"image\")\r\n","# cv_imshow(image_float, \"image float\")\r\n","#\r\n","# cv2.waitKey(0)           ### na końcu programu - oczekiwanie na reakcję użytkownika\r\n","# cv2.destroyAllWindows()  ### należy pamiętać o zniszczeniu okien!!!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ybLPvBMF_8k"},"source":["**UWAGA:** W środowisku Colab funkcja `cv2.imshow()` została zablokowana, zamiast niej polecane jest użycie funkcji `cv2_imshow()` z pakietu `google.colab.patches`, funkcja ta przyjmuje tylko jeden argument: obraz do wyświetlenia."]},{"cell_type":"code","metadata":{"id":"XJDUlSmcF8Os"},"source":["from google.colab.patches import cv2_imshow\r\n","\r\n","cv2_imshow(image)\r\n","\r\n","image_float = image.astype(np.float32) \r\n","# image_float = image*1. ### wykorzystanie operacji arytmetycznej do zmiany typu danych\r\n","print(f\"image_float, wymiary: {image_float.shape}, typ danych: {image_float.dtype}, wartości: {image_float.min()} - {image_float.max()}\")\r\n","\r\n","cv2_imshow(image_float)  ### cv2_imshow wyświetla obrazy z wartościami rzeczywistymi w sposób prawidłowy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LGAp3WBUe6vT"},"source":["### Wyświetlanie obrazu z wykorzystaniem pakietu `matplotlib.pyplot`"]},{"cell_type":"markdown","metadata":{"id":"iwq6Z4l0sHEN"},"source":["Funckja `plt.imshow()` może dokonywać automatycznego skalowania wartości pikseli do pełnego przedziału wartości ('rozciągnięcie histogramu'), aby tego uniknąć należy jawnie podać minimalną i maksymalną wartość.\r\n","\r\n","Funkcja `plt.show()` powoduje wyświetlenie wszystkich utworzonych okien i zablokowanie programu do czasu ich zamknięcia; wiele środowisk programistycznych (np. Spyder, PyCharm, Google Colab) potrafi wyświetlać 'okna' `matlplotlib.pyplot` w ramach swojego interfejsu graficznego - wywołanie `plt.show()` nie jest wtedy konieczne w celu wyświetlenia obrazu (może natomiast wymusić jego wyświetlenie w tym momencie), ale też obrazy wyświetlane są z reguły w ograniczonych rozmiarach - do 'dokładnego' ich oglądania warto zapisać je do pliku i otworzyć w 'zewnętrznej' przeglądarce obrazów."]},{"cell_type":"code","metadata":{"id":"x9q9wHMGfEQ8"},"source":["def plt_imshow(img, img_title=\"image\"):\r\n","    plt.figure() \r\n","    plt.title(img_title) \r\n","    # plt.imshow(img, cmap=\"gray\")  ### możliwe automatyczne skalowanie wartości pikseli\r\n","    plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)  ### bez skalowania wartości pikseli\r\n","    plt.xticks([]), plt.yticks([])\r\n","    plt.show()\r\n","\r\n","plt_imshow(image)\r\n","\r\n","image_dark = cv2.imread(data_dir+\"lena_mono_dark.png\", cv2.IMREAD_UNCHANGED)\r\n","print(f\"image_dark, wymiary: {image_dark.shape}, typ danych: {image_dark.dtype}, wartości: {image_dark.min()} - {image_dark.max()}\")\r\n","plt_imshow(image_dark, \"image_dark\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jaKFS9X5g0Bq"},"source":["### Funkcje pomocnicze"]},{"cell_type":"markdown","metadata":{"id":"GKBks-kasYQX"},"source":["Pomocnicze funkcje, aby można było łatwo zmieniać sposób wyświetalania obrazów i wypisywania komunikatów bez konieczności modyfikowania dalszych przykładów."]},{"cell_type":"code","metadata":{"id":"b_OaLucVhGgr","executionInfo":{"status":"ok","timestamp":1615284307321,"user_tz":-60,"elapsed":446,"user":{"displayName":"Grzegorz Galiński","photoUrl":"","userId":"07677391325184183263"}}},"source":["# imshow = cv_imshow   ### wyświetlanie z użyciem cv2\r\n","# imshow = plt_imshow  ### wyświetlanie z użyciem matplotlib\r\n","\r\n","def imshow(img, img_title=\"image\"):  ### 'opakowanie' na cv2_imshow(), żeby 'uzgodnić' parametry wywołania\r\n","  cv2_imshow(img) \r\n","\r\n","def printi(img, img_title=\"image\"):\r\n","    print(f\"{img_title}, wymiary: {img.shape}, typ danych: {img.dtype}, wartości: {img.min()} - {img.max()}\")"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6LCLYX4AiD_C"},"source":["# Odczytywanie wartości pikseli i ich modyfikacja."]},{"cell_type":"markdown","metadata":{"id":"QKOZGGMksjgu"},"source":["Dane zwracane przez `cv2.imread()` są tablicami pakietu NumPy (`numpy.ndarray`) i można nimi operować jak każdą inną tablicą NumPy.\r\n","\r\n","Obowiązuje notacja macierzowa, czyli `[wiersz, kolumna]`. Konstrukcja '`start:end`' w określeniu indeksów do tablicy pozwala na odczyt lub modyfikację całego zakresu wierszy bądź kolumn, włącznie z wierszem/kolumną o indeksie `start`, ale już z wyłączeniem `end`. Można pominąć wartości `start` i/lub `end` - zostaną wtedy zastosowane wartości domyślne (początek danych dla `start` i ich koniec dla `end`), można też podawać wartości ujemne (co oznacza określenie indeksu od końca). Na przykład:\r\n","* `[0:50, 50:100]` - wiersze od 0 do 49 włącznie, kolumny od 50 do 99 włącznie,\r\n","* `[:50, 50:]` - wiersze od początku do 49 włącznie, kolumny od 50 do końca,\r\n","* `[:, 10:-1]` - wszystkie wiersze, kolumny od 10 do przedostatniej (pominięta 1 ostatnia kolumna),\r\n","* `[:, :]` - wszystkie wiersze i kolumny."]},{"cell_type":"code","metadata":{"id":"gvMQSO1SiWfw"},"source":["px = image[0, 0]\r\n","print(f\"px = {px}\")\r\n","\r\n","image[0,0] = 255\r\n","print(f\"img[0,0] = {image[0, 0]}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L41-eQC1iyjI"},"source":["# for x in range(50):  ### zmiana wartości pojedynczych pikseli - może być nieefektywna\r\n","#     for y in range(50):\r\n","#         image[x,y] = 255\r\n","\r\n","image[0:50, 0:50] = 255\r\n","image[0:25, 0:25] = np.ones((25, 25))*192  ### wymiary tablicy modyfikującej muszą być zgodne z zakresem określonym w tablicy modyfikowanej\r\n","\r\n","imshow(image, \"zmienione piksele\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ESzHxV0bjDYQ"},"source":["Zalecaną metodą dostępu/modyfikacji wartości pojedynczych pikseli jest użycie metod `item()` i `itemset()`.\r\n","\r\n","Metody te zawsze operują na wartościach skalarnych, więc w przypadku obrazów barwnych należy oddzielnie odczytywać/modyfikować wartość każdej składowej.\r\n"]},{"cell_type":"code","metadata":{"id":"UwUpJk4HjtYE"},"source":["val = image.item(10, 10)\r\n","print(f\"val: {val}\")\r\n","\r\n","image.itemset((10, 10), 0)\r\n","image.itemset((10, 11), 0)\r\n","image.itemset((11, 10), 0)\r\n","image.itemset((11, 11), 0)\r\n","\r\n","imshow(image, \"zmieniony piksel\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nkmTvjI4n94C"},"source":["Porównianie czasu wykonania operacji ustawiającej wartości pikseli dwoma metodami:"]},{"cell_type":"code","metadata":{"id":"9Vqsqef0oEoJ"},"source":["def solaryzacja_m1(img):\r\n","    t1 = time.time()\r\n","    solarizedimg_m1 = np.zeros(img.shape, np.uint8)  ### utworzenie 'pustego' obrazu o wymaganych wymiarach\r\n","    for h in range(0, img.shape[0]):\r\n","        for w in range(0, img.shape[1]):\r\n","            if img[h][w] <= 127:\r\n","                solarizedimg_m1[h][w] = 2*img[h][w]\r\n","            else:\r\n","                solarizedimg_m1[h][w] = 2*(255-img[h][w])\r\n","    # solarizedimg_m1 = np.clip(solarizedimg_m1, 0, 255)\r\n","    t2 = time.time()\r\n","    print(f\"czas metody 1: {t2-t1}\")\r\n","    printi(solarizedimg_m1, \"solarizedimg_m1\")\r\n","    imshow(solarizedimg_m1, \"solarizedimg_m1\")\r\n","\r\n","def solaryzacja_m2(img):\r\n","    t1 = time.time()\r\n","    solarizedimg_m2 = np.zeros(img.shape, np.uint8)\r\n","    for h in range(0, img.shape[0]):\r\n","        for w in range(0, img.shape[1]):\r\n","            val = img.item(h,w)\r\n","            if val <= 127:\r\n","                solarizedimg_m2.itemset((h, w), 2*val)\r\n","            else:\r\n","                solarizedimg_m2.itemset((h, w), 2*(255-val))\r\n","    # solarizedimg_m2 = np.clip(solarizedimg_m2, 0, 255)\r\n","    t2 = time.time()\r\n","    print(f\"czas metody 2: {t2-t1}\")\r\n","    printi(solarizedimg_m2, \"solarizedimg_m2\")\r\n","    imshow(solarizedimg_m2, \"solarizedimg_m2\")\r\n","\r\n","solaryzacja_m1(image) \r\n","solaryzacja_m2(image) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zMH8qYIMorYf"},"source":["Do modyfikacji wartości pikseli całego obrazu można wykorzystywać operacje arytmetyczne.\r\n","\r\n","**UWAGA:** ze względu na zapis wartości pikseli jako liczb całkowitych `uint8`, bardzo łatwo jest przekroczyć zakres wartości [0, 255], co skutkuje 'zniekształceniem' obrazu.\r\n"]},{"cell_type":"code","metadata":{"id":"-8IHnaKdq6oY"},"source":["# result1 = image + np.ones(image.shape, dtype=image.dtype)*32  ### przekroczenie zakresu wartości!\r\n","result1 = image + 32  ### przekroczenie zakresu wartości!\r\n","printi(result1, \"image+32\")\r\n","imshow(result1, \"image+32\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iLZwlcoYq_Hf"},"source":["# result2 = image - np.ones(image.shape, dtype=image.dtype)*32  ### przekroczenie zakresu wartości!\r\n","result2 = image - 32  ### przekroczenie zakresu wartości!\r\n","printi(result2, \"image-32\")\r\n","imshow(result2, \"image-32\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YMYcajkdtHkY"},"source":["OpenCV dostarcza funkcje automatycznie obsługujące ograniczenie wartości do poprawnego zakresu."]},{"cell_type":"code","metadata":{"id":"qjFtnNKctOFw"},"source":["result_add = cv2.add(image, np.ones(image.shape, dtype=image.dtype)*128)  ### -> automatyczne ograniczenie wartości do 255!\r\n","printi(result_add, \"result_add\")\r\n","imshow(result_add, \"result_add\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RUP1m7IetiOl"},"source":["result_subtr = cv2.subtract(image, np.ones(image.shape, dtype=image.dtype)*128)  ### -> automatyczne ograniczenie wartości do 0!!!\r\n","printi(result_subtr, \"result_subtr\")\r\n","imshow(result_subtr, \"result_subtr\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uck19jHYuSSW"},"source":["##### blending: res = A*img1 + B*img2 + C\r\n","result_blend1 = cv2.addWeighted(image, 0.1, np.ones(image.shape, dtype=image.dtype)*128, 0.9, 0)\r\n","printi(result_blend1, \"result_blend1\")\r\n","imshow(result_blend1, \"result_blend1\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w2FbmC8HuiZs"},"source":["##### parametrem może być również skalar (wtedy można też po prostu wykorzystać parametr C): \r\n","result_blend2 = cv2.addWeighted(image, 1, 128, -1, 0)  ### -> image-128\r\n","# result_blend2 = cv2.addWeighted(image, 1, 0, 0, -128)  ### -> image-128\r\n","printi(result_blend2, \"result_blend2\")\r\n","imshow(result_blend2, \"result_blend2\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KyYKfZRdusKI"},"source":["# Usuwanie szumu z obrazu (*denoising*, *blurring*)"]},{"cell_type":"markdown","metadata":{"id":"uCgkfzKquxOF"},"source":["OpenCV dostarcza gotowe funkcje do usuwania szumu:\r\n","* `cv2.blur()` - filtr uśredniający (liniowy, dolnoprzepustowy),\r\n","* `cv2.GaussianBlur()` - filtr Gaussa (liniowy, dolnoprzepustowy),\r\n","* `cv2.medianBlur()` - filtr medianowy (nieliniowy).\r\n","\r\n","Rozmiar maski filtru ustalany jest parametrami wywołania funkcji.\r\n","Ponadto dla filtru Gaussa można okreslić odchylenie standardowe \r\n","(podanie wartosci `0` oznacza automatyczne wyliczenie wartości na podstawie rozmiaru maski).\r\n"]},{"cell_type":"markdown","metadata":{"id":"hcPBq7xnvmIT"},"source":["#### Obraz zaszumiony szumem gaussowskim"]},{"cell_type":"code","metadata":{"id":"2PPwyLnQvIeF"},"source":["image_noise = cv2.imread(data_dir+\"lena_mono_noise.png\", cv2.IMREAD_UNCHANGED) \r\n","printi(image_noise, \"image_noise\")\r\n","imshow(image_noise, \"image_noise\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HNhRS2i0vX03"},"source":["blur_img = cv2.blur(image_noise, (3, 3))\r\n","printi(blur_img, \"blur_img\")\r\n","imshow(blur_img, \"blur_img\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"80-uGAQGvbnZ"},"source":["gblur_img = cv2.GaussianBlur(image_noise, (5, 5), 0)\r\n","printi(gblur_img, \"gblur_img\")\r\n","imshow(gblur_img, \"gblur_img\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GjE4UGPovgF4"},"source":["median_img = cv2.medianBlur(image_noise, 3) \r\n","printi(median_img, \"median_img\")\r\n","imshow(median_img, \"median_img\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cUdF2BLxvvrS"},"source":["#### Obraz zaszumiony szumem impulsowym ('sól i pieprz')"]},{"cell_type":"code","metadata":{"id":"iXdT6s6Hvz7F"},"source":["image_inoise = cv2.imread(data_dir+\"lena_mono_inoise.png\", cv2.IMREAD_UNCHANGED) \r\n","printi(image_inoise, \"image_inoise\")\r\n","imshow(image_inoise, \"image_inoise\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uJKGX42Ev8RV"},"source":["blur_imgi = cv2.blur(image_inoise, (3, 3))\r\n","printi(blur_imgi, \"blur_imgi\")\r\n","imshow(blur_imgi, \"blur_imgi\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SYegB57LwAar"},"source":["gblur_imgi = cv2.GaussianBlur(image_inoise, (5, 5), 0)\r\n","printi(gblur_imgi, \"gblur_imgi\")\r\n","imshow(gblur_imgi, \"gblur_imgi\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HWkrnDmwwChh"},"source":["median_imgi = cv2.medianBlur(image_inoise, 3) \r\n","printi(median_imgi, \"median_imgi\")\r\n","imshow(median_imgi, \"median_imgi\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fUg41rf3LZBf"},"source":["#### Obliczenie PSNR"]},{"cell_type":"code","metadata":{"id":"9RMwrSc5LhFv"},"source":["def calcPSNR(img1, img2):\r\n","  imax = 255.**2  ### zakładana wartość pikseli z przedziału [0, 255]\r\n","  ##### w różnicy obrazów istotne są wartości ujemne, dlatego img1 konwertowany do typu np.float64 (liczby rzeczywiste) aby nie ograniczać wyniku do przedziału [0, 255]\r\n","  mse = ((img1.astype(np.float64)-img2)**2).sum()/img1.size  ### img1.size - liczba elementów w img1, ==img1.shape[0]*img1.shape[1] dla obrazów mono, ==img1.shape[0]*img1.shape[1]*img1.shape[2] dla obrazów barwnych\r\n","  return 10.0*np.log10(imax/mse)\r\n","\r\n","image = cv2.imread(data_dir+\"lena_mono.png\", cv2.IMREAD_UNCHANGED)\r\n","psnr = calcPSNR(image, gblur_img)\r\n","print(psnr)\r\n","psnr = calcPSNR(image, gblur_imgi)\r\n","print(psnr)\r\n","psnr = calcPSNR(image, median_imgi)\r\n","print(psnr)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y9gaf3PBwNms"},"source":["# Detekcja krawędzi w obrazie"]},{"cell_type":"markdown","metadata":{"id":"bw3fM0mowPVQ"},"source":["OpenCV dostarcza gotowe funkcje do wykrywania krawędzi w obrazie:\r\n","* `cv2.Sobel()` - bazującą na gradiencie (pierwsza pochodna) wartości pikseli,\r\n","* `cv2.Laplacian()` - bazującą na laplasjanie (druga pochodna) wartości pikseli.\r\n","\r\n","Specyfiką tego typu operacji jest to, że w wyniku moga pojawić się również wartości ujemne, dlatego należy ustalić format danych wynikowych np. na liczby rzeczywiste (np. `cv2.CV_64F` lub `cv2.CV_32F`, co odpowiada `np.float64` i `np.float32` odpowiednio), aby te wartości nie zostały 'zgubione'.\r\n","\r\n","Operacja detekcji krawędzi jest bardzo czuła na szum występujący w obrazie (generowanych jest wiele 'mikrokrawędzi'), dlatego czasami warto poddać obraz wcześniejszej operacji wygładzania.\r\n","\r\n","**UWAGA:** do wyświetlania obrazów brana jest wartość bezwzględna pikseli (`np.abs()`). Nie należy jednak tego robić w każdej sytuacji, jeśli obraz krawędziowy ma być wykorzystywany później do innych operacji (np. wyostrzania obrazu), to informacja o znaku jest bardzo istotna i nie może zostać utracona czy zmodyfikowana!\r\n"]},{"cell_type":"code","metadata":{"id":"NfoA2zuswJeH"},"source":["image = cv2.imread(data_dir+\"lena_mono.png\", cv2.IMREAD_UNCHANGED)\r\n","# image = cv2.imread(data_dir+\"lena_mono_noise.png\", cv2.IMREAD_UNCHANGED)\r\n","# image = cv2.imread(data_dir+\"lena_mono_inoise.png\", cv2.IMREAD_UNCHANGED)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KLFnNwqixrZm"},"source":["sobx_img = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)/4  ### gradient w kierunku x - krawędzie pionowe\r\n","soby_img = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)/4  ### gradient w kierunku y - krawędzie poziome\r\n","printi(sobx_img, \"sobx_img\")\r\n","printi(soby_img, \"soby_img\")\r\n","imshow(np.abs(sobx_img), \"sobx_img\")\r\n","imshow(np.abs(soby_img), \"soby_img\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OuBzPE46xL97"},"source":["##### suma gradientów - pełna informacja o krawędziach; wartości pikseli jako liczby rzeczywiste - nie ma niebezpieczeństwa przekroczenia zakresu\r\n","sob_img = sobx_img + soby_img \r\n","printi(sob_img, \"sob_img\")\r\n","imshow(np.abs(sob_img), \"sob_img\")\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3-kihGhzxbj3"},"source":["sob_img2 = cv2.Sobel(image, cv2.CV_64F, 1, 1, ksize=3)  ### gradienty w kierunku x i y\r\n","printi(sob_img2, \"sob_img2\")\r\n","imshow(np.abs(sob_img2), \"sob_img2\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mezw70WfxgZ8"},"source":["lap_img = cv2.Laplacian(image, cv2.CV_64F) \r\n","printi(lap_img, \"lap_img\")\r\n","imshow(np.abs(lap_img), \"lap_img\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qWXaOxbTx7Yv"},"source":["OpenCV dostarcza również gotową implementację algorytmu Canny'ego detekcji krawędzi, którego rezultatem jest nie 'surowy' obraz gradientowy, lecz wynik wieloetapowego procesu wykrywania i przetwarzania krawędzi w postaci obrazu binarnego, na którym krawędzie oznaczone są białymi pikselami. (Więcej: \r\n","[opis algorytmu Canny'ego w OpenCV](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_canny/py_canny.html) )\r\n"]},{"cell_type":"code","metadata":{"id":"DWaof9i0yfdY"},"source":["canny_img = cv2.Canny(image, 75, 200)\r\n","printi(canny_img, \"canny_img\")\r\n","imshow(canny_img, \"canny_img\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BAPqoHj9yraD"},"source":["# Generyczna filtracja obrazu"]},{"cell_type":"markdown","metadata":{"id":"ax-PiBCXyuCo"},"source":["OpenCV dostarcza również generyczną funkcję do liniowej filtracji obrazu filtrem o danej masce: `cv2.filter2D()`.\r\n","Paremetry tej funkcji pozwalają określić typ danych wyjściowych (np. `cv2.CV_8U` - liczby całkowite z przedziału [0, 255], `cv2.CV_64F`, `cv2.CV_32F` - liczby rzeczywiste 64- lub 32-bitowej precyzji; podanie wartości `-1` oznacza wynik takiego samego typu jak dane w obrazie wejściowym), oraz maskę filtru.\r\n"]},{"cell_type":"markdown","metadata":{"id":"-m9mvFaJzDKI"},"source":["#### Filtracja filtrem dolnoprzepustowym o rozmiarze 5x5, będącym przybliżeniem filtru Gaussa"]},{"cell_type":"code","metadata":{"id":"iYax85YJzA5V"},"source":["mask_low = np.array([\r\n","    [1,  4,  7,  4, 1], \r\n","    [4, 20, 33, 20, 4], \r\n","    [7, 33, 55, 33, 7], \r\n","    [4, 20, 33, 20, 4], \r\n","    [1,  4,  7,  4, 1]], np.float32)\r\n","mask_low = mask_low/mask_low.sum()  ### normalizacja maski filtru\r\n","\r\n","lowpass_img = cv2.filter2D(image, -1, mask_low)  ### '-1' -> dane wyjściowe w takim samym formacie jak dane wejściowe\r\n","printi(lowpass_img, \"lowpass_img\")\r\n","imshow(lowpass_img, \"lowpass_img\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l_gWGa0czPPP"},"source":["#### Filtracja filtrem górnoprzepustowym - laplasjan w czterech kierunkach"]},{"cell_type":"code","metadata":{"id":"WZN2s1YAzT4d"},"source":["mask_lap = np.array([\r\n","    [-1, -1, -1], \r\n","    [-1,  8, -1], \r\n","    [-1, -1, -1]], np.float32)\r\n","\r\n","highpass_img = cv2.filter2D(image, cv2.CV_64F, mask_lap)  ### ustalony format danych wyjściowych na liczby rzeczywiste, ze względu na wartości ujemne w wyniku filtracji górnoprzepustowej\r\n","printi(highpass_img, \"highpass_img\")\r\n","imshow(np.abs(highpass_img), \"highpass_img\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Syz-yK-lZrME"},"source":["# Operacje morfologiczne"]},{"cell_type":"markdown","metadata":{"id":"TiiYKoqSZuY_"},"source":["OpenCV dostarcza gotowe funkcje do wykonywania operacji morfologicznych na obrazie:\r\n","* `cv2.erode()` - erozja,\r\n","* `cv2.dilate()` - dylacja\r\n","* `cv2.morphologyEx()` - bardziej złożone operacje, m.in. otwarcie, domknięcie, gradient.\r\n","\r\n","Parametry funkcji pozwalają określić jądro (maskę) operacji, nie podanie żadnej oznacza wykorzystanie domyślnej maski o rozmiarach 3x3.\r\n","\r\n","Operacje morfologiczne z reguły wykonywane są dla obrazów binarnych. Binaryzacji obrazu monochromatycznego można dokonać prostymi operacjami modyfikacji wartości oraz funkcjami z pakietu NumPy, ale OpenCV dostarcza również gotowe funkcje, pozwalające na progowanie obrazu na różne sposoby (nie w każdym trybie progowania wynikiem będzie obraz binarny): `cv2.threshold()` oraz `cv2.adaptiveThreshold()`."]},{"cell_type":"code","metadata":{"id":"w6orDIYUbx7w"},"source":["binary_img = np.where(image >= 128, np.uint8(255), np.uint8(0))  ### wymuszenie liczb 8-bitowych -> np.uint8()\r\n","printi(binary_img, \"binary_img\")\r\n","imshow(binary_img, \"binary_img\")\r\n","\r\n","th_val, thresh_img = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)  ### w niektórych trybach próg jest wyznaczany automatycznie i funkcja zwraca jego wartość\r\n","printi(thresh_img, \"thresh_img\")\r\n","imshow(thresh_img, \"thresh_img\")\r\n","\r\n","adaptth_img = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 8)  ### przydatne szczegółnie przy \"nierównym\" oświetleniu w obrazie\r\n","printi(adaptth_img, \"adaptth_img\")\r\n","imshow(adaptth_img, \"adaptth_img\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P-K7eydhgGRW"},"source":["erode_img = cv2.erode(thresh_img, None)\r\n","printi(erode_img, \"erode_img\")\r\n","imshow(erode_img, \"erode_img\")\r\n","\r\n","morph_kernel = np.ones((5, 5), dtype=np.uint8)\r\n","dilate_img = cv2.dilate(thresh_img, morph_kernel)\r\n","printi(dilate_img, \"dilate_img\")\r\n","imshow(dilate_img, \"dilate_img\")\r\n","\r\n","open_close_img = cv2.morphologyEx(cv2.morphologyEx(thresh_img, cv2.MORPH_OPEN, None), cv2.MORPH_CLOSE, None)  ### cv2.MORPH_GRADIENT, cv2.MORPH_ERODE, cv2.MORPH_DILATE\r\n","printi(open_close_img, \"open_close_img\")\r\n","imshow(open_close_img, \"open_close_img\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Ojsp0mmzf2C"},"source":["# Wyznaczanie i rysowanie histogramu"]},{"cell_type":"markdown","metadata":{"id":"oVOd2vlvzk45"},"source":["W pakiecie `matplotlib.pyplot` jest gotowa funkcja, która obliczy i narysuje histogram: `plt.hist()` (jeśli nie chce się rysować histogramu, a tylko go policzyć, można skorzystać z analogicznej funkcji w pakiecie `numpy`: `np.histogram()`)."]},{"cell_type":"code","metadata":{"id":"4wcfGReWzj7j"},"source":["plt.figure()\r\n","hist_plt = plt.hist(image.flatten(), 256, range=[0.0, 255.0])\r\n","# print(hist_plt[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IjXxgv9mzxXI"},"source":["OpenCV również dostarcza funkcję do wyznaczenia histogramu (ma być dużo szybsza): `cv2.calcHist()`.\r\n","\r\n","`cv2.calcHist()` może wyznaczyć histogram dla wielu obrazów równocześnie, dlatego parametry tej funkcji przekazuje się jako tablice.\r\n","\r\n","`cv2.calcHist()` zwraca wynik w postaci tablicy dwuwymiarowej, konwersji na tablicę jednowymiarową można dokonać za pomocą funkcji `np.flatten()`.\r\n","\r\n","Ze względu na inny sposób traktowania górnego kresu zakresu zmienności wartości pikseli, zakres wartości dla `cv2.calcHist()` należy okrelić jako [0, 256], aby uzyskać wynik identyczny jak dla `plt.hist()` i zakresu [0, 255].\r\n","\r\n","Do narysowania najwygodniej jest wykorzystać również `matplotlib.pyplot`.\r\n"]},{"cell_type":"code","metadata":{"id":"QKH89J110zcd"},"source":["hist_cv = cv2.calcHist([image], [0], None, [256], [0, 256])\r\n","hist_cv = hist_cv.flatten()\r\n","# print(hist_cv)\r\n","print(f\"suma różnic wartosci histogramów: {np.abs(hist_cv.flatten()-hist_plt[0]).sum()}\")\r\n","\r\n","plt.figure()\r\n","plt.plot(hist_cv, color=\"blue\")\r\n","plt.xlim([0,256])\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s0L7W0sh1AaS"},"source":["### Wyrównanie histogramu"]},{"cell_type":"code","metadata":{"id":"ZnhY5ARb1G4g"},"source":["image = cv2.imread(data_dir+\"lena_mono.png\", cv2.IMREAD_UNCHANGED)\r\n","printi(image, \"image\")\r\n","imshow(image, \"image\")\r\n","\r\n","equ_img = cv2.equalizeHist(image)\r\n","printi(equ_img, \"equ_img\")\r\n","imshow(equ_img, \"equ_img\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uJ3QcPKE1OUc"},"source":["image_dark = cv2.imread(data_dir+\"lena_mono_dark.png\", cv2.IMREAD_UNCHANGED)\r\n","printi(image_dark, \"image_dark\")\r\n","imshow(image_dark, \"image_dark\")\r\n","\r\n","equ_imgdark = cv2.equalizeHist(image_dark)\r\n","printi(equ_imgdark, \"equ_imgdark\")\r\n","imshow(equ_imgdark, \"equ_imgdark\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0jK6FsvI1WqI"},"source":["# Obrazy barwne"]},{"cell_type":"markdown","metadata":{"id":"yreTTihc8M_s"},"source":["#### Przykłady przedstawionych  wcześniej operacji zastosowanych do obrazu barwnego"]},{"cell_type":"code","metadata":{"id":"WHJI60kb67tS"},"source":["colimage = cv2.imread(data_dir+\"lena_col.png\")\r\n","printi(colimage, \"colimage\")\r\n","imshow(colimage, \"colimage\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gQ_0tQ857rPA"},"source":["col_neg = 255-colimage  ### negatyw\r\n","printi(col_neg, \"col_neg\")\r\n","imshow(col_neg, \"col_neg\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-CblkVkA7w2E"},"source":["col_gblur = cv2.GaussianBlur(colimage, (9, 9), 0)\r\n","printi(col_gblur, \"col_gblur\")\r\n","imshow(col_gblur, \"col_gblur\")\r\n","\r\n","col_mblur = cv2.medianBlur(colimage, 7)\r\n","imshow(col_mblur)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sbdcZ253706C"},"source":["col_edgesx = cv2.Sobel(colimage, cv2.CV_64F, 1, 0, ksize=3)/4\r\n","col_edgesy = cv2.Sobel(colimage, cv2.CV_64F, 0, 1, ksize=3)/4\r\n","printi(col_edgesx, \"col_edgesx\")\r\n","printi(col_edgesy, \"col_edgesy\")\r\n","imshow(col_edgesx, \"col_edgesx\")\r\n","imshow(col_edgesy, \"col_edgesy\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eis93kvaYyDs"},"source":["col_lapl = cv2.Laplacian(colimage, cv2.CV_64F) \r\n","printi(col_lapl, \"col_lapl\")\r\n","imshow(np.abs(col_lapl), \"col_lapl\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"12JPXABK8Aps"},"source":["col_canny = cv2.Canny(colimage, 75, 150)\r\n","printi(col_canny, \"col_canny\")\r\n","imshow(col_canny, \"col_canny\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rqUSi7UR8Imn"},"source":["col_lowpass = cv2.filter2D(colimage, -1, mask_low)  #'-1' - dane wyjsciowe w takim samym formacie jak dane wejsciowe\r\n","printi(col_lowpass, \"col_lowpass\")\r\n","imshow(col_lowpass, \"col_lowpass\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7-xFrAl38nEG"},"source":["## Konwersja przestrzeni kolorów"]},{"cell_type":"markdown","metadata":{"id":"KsvQXR-i854d"},"source":["Konwersja z BGR (domyślny format w OpenCV) do HSV.\r\n","\r\n","Dostępne są dwa typy konwersji:\r\n","* `cv2.COLOR_BGR2HSV` - zakres wartości H to [0, 179]\r\n","* `cv2.COLOR_BGR2HSV_FULL` - zakres wartości H to [0, 255]\r\n","\r\n","W pierwszym przypadku, przy samodzielnej modyfikacji wartości H należy zadbać o odpowiednie ich ograniczenie do przedziału [0, 179] (wartość `180` przechodzi w `0`, wartosć `-1` - w `179`) przy jednoczesnym nieprzekroczeniu zakresu [0, 255] (zakres typu `uint8`).\r\n","\r\n","W drugim przypadku modyfikacje wartosci H w sposób automatyczny są 'zawijane' w przedziale [0, 255] i mogą być prostsze w zapisie.\r\n","\r\n","Dla wartosci S i V obie konwersje sa równoważne.\r\n"]},{"cell_type":"markdown","metadata":{"id":"hFsFjJTi9boX"},"source":["#### Modyfikacja nasycenia"]},{"cell_type":"code","metadata":{"id":"Bte4w0019ZrX"},"source":["col_hsv = cv2.cvtColor(colimage, cv2.COLOR_BGR2HSV)\r\n","col_hsv[:, :, 1] = cv2.multiply(col_hsv[:, :, 1], 2)\r\n","col_sat = cv2.cvtColor(col_hsv, cv2.COLOR_HSV2BGR)\r\n","imshow(col_sat, \"col_sat\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VQF7pv779lB-"},"source":["#### Modyfikacja odcienia"]},{"cell_type":"code","metadata":{"id":"wRqzEIZG9pUQ"},"source":["col_hsv = cv2.cvtColor(colimage, cv2.COLOR_BGR2HSV_FULL)\r\n","col_hsv[:, :, 0] += 90  ### nie cv2.add() albo podobna, bo nie chcemy 'obcięcia' wartości, a właśnie ich 'zawinięcia'\r\n","col_hue = cv2.cvtColor(col_hsv, cv2.COLOR_HSV2BGR_FULL)\r\n","imshow(col_hue, \"col_hue\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u000TUPs9wqF"},"source":["#### Modyfikacja jasności"]},{"cell_type":"code","metadata":{"id":"fivZXp0x9zWm"},"source":["col_hsv = cv2.cvtColor(colimage, cv2.COLOR_BGR2HSV)\r\n","col_hsv[:, :, 2] = cv2.subtract(col_hsv[:, :, 2], 64)  ### a tu właśnie 'obcięcie' jest pożądane\r\n","col_val = cv2.cvtColor(col_hsv, cv2.COLOR_HSV2BGR)\r\n","imshow(col_val, \"col_val\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FMo7qgUC99Jj"},"source":["#### Efekt sepii (lub dowolnego innego koloru)"]},{"cell_type":"code","metadata":{"id":"_yQIjrU19_Ic"},"source":["##### można wykorzystać obraz monochromatyczny (jedna składowa) i dokonać jego konwersji na obraz 'barwny' (trzy składowe, wszystkie o takiej samej wartości)\r\n","# image = cv2.imread(\"lena_mono.png\", cv2.IMREAD_UNCHANGED)\r\n","# image_gray = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\r\n","\r\n","##### można też obraz monochromatyczny od razu wczytać jako 'barwny' (obraz barwny należy najpierw skonwertować na szaroodcieniowy)\r\n","image_gray = cv2.imread(data_dir+\"lena_mono.png\", cv2.IMREAD_COLOR) \r\n","\r\n","imshow(image_gray, \"image_gray\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ABf3znVz_JkV"},"source":["image_hsv = cv2.cvtColor(image_gray, cv2.COLOR_BGR2HSV)\r\n","image_hsv[:, :, 0] = 25  ### trzeba ustawić odcień...\r\n","image_hsv[:, :, 1] = 96  ### oraz nasycenie\r\n","image_col = cv2.cvtColor(image_hsv, cv2.COLOR_HSV2BGR)\r\n","imshow(image_col, \"image_col\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_k44O4S2_tAi"},"source":["#### Paleta barw HSV"]},{"cell_type":"code","metadata":{"id":"C3RH543i_4KC"},"source":["def generateHSVCircle(rad):  ### wersja z obliczaniem wartości dla każdego piskela\r\n","    ##### rad - promień palety\r\n","    sz = 2*rad+1   ### całkowity rozmiar (szerokość i wysokość) obrazu wynikowego\r\n","    cx = cy = rad  ### centrum palety w obrazie\r\n","    \r\n","    img_hsv = np.zeros((sz, sz, 3), dtype=np.uint8)  ### pusty obraz o pożądanych rozmiarach\r\n","\r\n","    for x in range(0, sz, 1):\r\n","        for y in range(0, sz, 1):\r\n","            dist = np.sqrt((x-cx)**2 + (y-cy)**2)\r\n","            if dist > rad: \r\n","                img_hsv.itemset((y, x, 0), 0)\r\n","                img_hsv.itemset((y, x, 1), 0)\r\n","                img_hsv.itemset((y, x, 2), 0)\r\n","            else:\r\n","                hue = np.degrees(np.arctan2(cy-y, x-cx))  ### np.arctan() daje wartości [-180, 180]...\r\n","                hue = np.round(hue/2)%180                 ### ...a potrzebne są [0, 180], dlatego '/2' i '%180' (% 'poprawi' zarówno ujemne, jak i zmieni 180 na 0)\r\n","                img_hsv.itemset((y, x, 0), hue)                     ### hue: zależnie od kąta, od 0 do 179 (180 to znowu 0)\r\n","                img_hsv.itemset((y, x, 1), np.round(dist/rad*255))  ### nasycenie: na brzegu max (255), maleje do 0 w środku\r\n","                img_hsv.itemset((y, x, 2), 255)                     ### value: zawsze max\r\n","    \r\n","    return cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\r\n","\r\n","def generateHSVCircle_v2(rad):  ### wersja z obliczeniami na macierzach (szybsza, ale zapis może mniej 'czytelny')\r\n","    ##### rad - promień palety\r\n","    sz = 2*rad+1   ### całkowity rozmiar (szerokość i wysokość) obrazu wynikowego\r\n","    cx = cy = rad  ### centrum palety w obrazie\r\n","    \r\n","    img_hsv = np.zeros((sz, sz, 3), dtype=np.uint8)  ### pusty obraz o pożądanych rozmiarach\r\n","    \r\n","    xx = np.tile(np.arange(-rad, rad+1, 1), (sz,1))\r\n","    yy = xx.T\r\n","    angles = np.degrees(np.arctan2(-yy, xx))  ### np.arctan() daje wartosci [-180, 180]...\r\n","    dists = np.sqrt(xx**2 + yy**2)\r\n","\r\n","    img_hsv[:,:,0] = np.round(angles/2)%180                             ### ...a Hue ma wartości [0, 180], dlatego '/2' i '%180' (% 'poprawi' zarówno wartości ujemne, jak i zmieni 180 na 0)\r\n","    img_hsv[:,:,1] = np.where(dists > rad, 0, np.round(dists/rad*255))  ### nasycenie: na brzegu max (255), maleje do 0 w środku, poza paletą też 0\r\n","    img_hsv[:,:,2] = np.where(dists > rad, 0, 255)                      ### value: w palecie zawsze max, poza paletą 0\r\n","    \r\n","    return cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\r\n","\r\n","t1 = time.time()\r\n","hsv_cir = generateHSVCircle_v2(256)\r\n","t2 = time.time()\r\n","print(f\"czas: {t2-t1}\")\r\n","imshow(hsv_cir, \"hsv_cir\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p2Xi1WxkQJWr"},"source":["## Wyrównanie histogramu"]},{"cell_type":"markdown","metadata":{"id":"yjMSsQUmRvl8"},"source":["`cv2.equalizeHist()` wymaga obrazów monochromatycznych (z jedną składową). \r\n","\r\n","Wyrównanie histogramu wykonane osobno dla każdej ze składowych RGB obrazu barwnego powoduje '*zniekształcenie*' barw w obrazie. Dla obrazów barwnych operację tę wykonuje się tylko dla składowej opisującej jasność, np. składowej Y w YCrCb/YUV (`cv2.COLOR_BGR2YCrCb` lub `cv2.COLOR_BGR2YUV`) - operacja do samodzielnego wykonania."]},{"cell_type":"code","metadata":{"id":"3Agl_H_bQI5J"},"source":["# equ_img = cv2.equalizeHist(colimage)  ### -> błąd wykonania"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i2dWNdOASmMJ"},"source":["equ_colimg = np.zeros(colimage.shape, dtype=colimage.dtype)  ### 'pusty' obraz wynikowy \r\n","\r\n","equ_colimg[:,:,0] = cv2.equalizeHist(colimage[:,:,0])  ### B -> cv2.imread() zwraca obrazy w formacie BGR\r\n","equ_colimg[:,:,1] = cv2.equalizeHist(colimage[:,:,1])  ### G\r\n","equ_colimg[:,:,2] = cv2.equalizeHist(colimage[:,:,2])  ### R\r\n","\r\n","imshow(equ_colimg, \"equ_colimg\")"],"execution_count":null,"outputs":[]}]}